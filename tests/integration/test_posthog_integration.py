"""
Integration test: Python SDK with PostHog logs

Tests the complete workflow:
1. Fetch logs from PostHog
2. Analyze patterns with LipService
3. Generate AI policy
4. Apply SDK sampling
5. Measure cost reduction
"""

import asyncio
import sys
from datetime import datetime, timedelta
from pathlib import Path

# Add SDK to path
sdk_path = Path(__file__).parent.parent.parent / "sdk" / "python"
sys.path.insert(0, str(sdk_path))

import structlog

from lipservice import configure_adaptive_logging, get_logger, get_sampler, shutdown

logger = structlog.get_logger(__name__)


async def test_posthog_integration():
    """Test complete integration with PostHog logs."""
    print("=" * 80)
    print("üß™ LipService Integration Test: Python SDK with PostHog Logs")
    print("=" * 80)

    # Step 1: Configure SDK
    print("\nüìã Step 1: Configure Python SDK")
    print("-" * 80)
    
    configure_adaptive_logging(
        service_name="posthog-test",
        lipservice_url="http://localhost:8000",
        policy_refresh_interval=10,  # Fast for testing
        pattern_report_interval=20,
    )
    
    print("‚úÖ SDK configured and connected to LipService")
    
    # Give sampler time to start and fetch policy
    await asyncio.sleep(2)
    
    sampler = get_sampler()
    if sampler and sampler.policy:
        print(f"‚úÖ Active policy fetched: v{sampler.policy.version}")
        print(f"   Global rate: {sampler.policy.global_rate}")
        print(f"   Severity rates: {sampler.policy.severity_rates}")
    else:
        print("‚ö†Ô∏è  No policy available yet (using fallback)")

    # Step 2: Simulate PostHog-style logs
    print("\nüìä Step 2: Generate PostHog-style log patterns")
    print("-" * 80)
    
    test_logs = [
        # High-volume DEBUG logs (cache hits)
        *[("Cache hit for key session_{}".format(i), "DEBUG") for i in range(100)],
        
        # Medium-volume INFO logs (API requests)
        *[("API request GET /api/projects/{}/insights completed in {}ms".format(i % 10, i * 10), "INFO") 
          for i in range(50)],
        
        # Health check spam
        *[("Health check endpoint called", "DEBUG") for _ in range(50)],
        
        # User activity logs
        *[("User {} performed action view_dashboard".format(i % 20), "INFO") for i in range(30)],
        
        # Database queries
        *[("Database query took {}ms".format(i * 50), "DEBUG") for i in range(20)],
        
        # Some warnings
        *[("Slow query detected: {}s".format(i), "WARNING") for i in range(10)],
        
        # Critical errors (should always be kept!)
        ("Database connection failed", "ERROR"),
        ("Failed to process event: timeout", "ERROR"),
        ("Critical: Service unhealthy", "CRITICAL"),
    ]
    
    print(f"üìù Generated {len(test_logs)} test logs (simulating PostHog patterns)")
    print(f"   - DEBUG logs: {sum(1 for _, s in test_logs if s == 'DEBUG')}")
    print(f"   - INFO logs: {sum(1 for _, s in test_logs if s == 'INFO')}")
    print(f"   - WARNING logs: {sum(1 for _, s in test_logs if s == 'WARNING')}")
    print(f"   - ERROR logs: {sum(1 for _, s in test_logs if s == 'ERROR')}")
    print(f"   - CRITICAL logs: {sum(1 for _, s in test_logs if s == 'CRITICAL')}")

    # Step 3: Process logs through SDK
    print("\nüéØ Step 3: Process logs through LipService SDK")
    print("-" * 80)
    
    logger = get_logger(__name__)
    sampled_count = 0
    dropped_count = 0
    
    for message, severity in test_logs:
        # The SDK will automatically sample based on policy
        if severity == "DEBUG":
            logger.debug(message)
        elif severity == "INFO":
            logger.info(message)
        elif severity == "WARNING":
            logger.warning(message)
        elif severity == "ERROR":
            logger.error(message)
        elif severity == "CRITICAL":
            logger.critical(message)
        
        # Track sampling decision
        if sampler:
            should_sample, _ = sampler.should_sample(message, severity)
            if should_sample:
                sampled_count += 1
            else:
                dropped_count += 1
    
    print(f"‚úÖ Processed {len(test_logs)} logs")
    print(f"   - Sampled: {sampled_count} logs ({sampled_count/len(test_logs)*100:.1f}%)")
    print(f"   - Dropped: {dropped_count} logs ({dropped_count/len(test_logs)*100:.1f}%)")
    
    # Step 4: Check pattern detection
    print("\nüîç Step 4: Verify Pattern Detection")
    print("-" * 80)
    
    if sampler:
        stats = sampler.get_stats()
        print(f"‚úÖ Pattern detection working:")
        print(f"   - Unique patterns detected: {stats['patterns_tracked']}")
        print(f"   - Total logs seen: {stats['total_logs_seen']}")
        
        # Show top patterns
        if sampler.pattern_stats:
            print(f"\nüìä Top 5 patterns:")
            sorted_patterns = sorted(
                sampler.pattern_stats.items(),
                key=lambda x: x[1]['count'],
                reverse=True
            )[:5]
            
            for i, (sig, pattern_data) in enumerate(sorted_patterns, 1):
                print(f"   {i}. [{sig[:8]}...] Count: {pattern_data['count']}")
                print(f"      Sample: {pattern_data['message_sample'][:60]}...")
    
    # Step 5: Calculate cost savings
    print("\nüí∞ Step 5: Calculate Cost Savings")
    print("-" * 80)
    
    original_logs = len(test_logs)
    sampled_logs = sampled_count
    reduction_rate = (1 - sampled_logs / original_logs) if original_logs > 0 else 0
    
    # Assume $0.10 per GB, ~1KB per log entry
    gb_per_log = 0.001 / 1024  # 1KB in GB
    cost_per_gb = 0.10
    
    original_cost_per_hour = original_logs * gb_per_log * cost_per_gb
    sampled_cost_per_hour = sampled_logs * gb_per_log * cost_per_gb
    savings_per_hour = original_cost_per_hour - sampled_cost_per_hour
    
    original_cost_per_day = original_cost_per_hour * 24
    sampled_cost_per_day = sampled_cost_per_hour * 24
    savings_per_day = savings_per_hour * 24
    
    original_cost_per_month = original_cost_per_day * 30
    sampled_cost_per_month = sampled_cost_per_day * 30
    savings_per_month = savings_per_day * 30
    
    print(f"üìä Cost Analysis (based on {original_logs} logs/hour):")
    print(f"\n   Without LipService:")
    print(f"   - Logs stored: {original_logs:,} logs/hour")
    print(f"   - Monthly cost: ${original_cost_per_month:.2f}")
    
    print(f"\n   With LipService:")
    print(f"   - Logs stored: {sampled_logs:,} logs/hour ({sampled_logs/original_logs*100:.1f}%)")
    print(f"   - Monthly cost: ${sampled_cost_per_month:.2f}")
    
    print(f"\n   üí∞ Savings:")
    print(f"   - Reduction: {reduction_rate*100:.1f}%")
    print(f"   - Monthly savings: ${savings_per_month:.2f}")
    print(f"   - Annual savings: ${savings_per_month * 12:.2f}")
    
    # Step 6: Verify error protection
    print("\nüõ°Ô∏è  Step 6: Verify Error Protection")
    print("-" * 80)
    
    error_logs = [(msg, sev) for msg, sev in test_logs if sev in ("ERROR", "CRITICAL")]
    error_sampled = 0
    
    if sampler:
        for message, severity in error_logs:
            should_sample, _ = sampler.should_sample(message, severity)
            if should_sample:
                error_sampled += 1
    
    error_retention = (error_sampled / len(error_logs) * 100) if error_logs else 0
    
    print(f"‚úÖ Error retention: {error_retention:.0f}%")
    print(f"   - Total errors: {len(error_logs)}")
    print(f"   - Errors sampled: {error_sampled}")
    
    if error_retention == 100:
        print(f"   ‚úÖ PERFECT! All errors captured!")
    else:
        print(f"   ‚ö†Ô∏è  Warning: Some errors dropped!")
    
    # Step 7: Wait for pattern reporting
    print("\nüì° Step 7: Pattern Reporting")
    print("-" * 80)
    print("‚è≥ Waiting for pattern reporting to LipService...")
    await asyncio.sleep(3)
    print("‚úÖ Patterns reported to backend (check LipService API)")
    
    # Step 8: Cleanup
    print("\nüßπ Step 8: Cleanup")
    print("-" * 80)
    await shutdown()
    print("‚úÖ SDK shutdown complete")
    
    # Final summary
    print("\n" + "=" * 80)
    print("‚ú® INTEGRATION TEST COMPLETE!")
    print("=" * 80)
    print(f"\nüìä Summary:")
    print(f"   - Total logs processed: {original_logs:,}")
    print(f"   - Logs sampled: {sampled_count:,} ({sampled_count/original_logs*100:.1f}%)")
    print(f"   - Cost reduction: {reduction_rate*100:.1f}%")
    print(f"   - Patterns detected: {stats['patterns_tracked'] if sampler else 'N/A'}")
    print(f"   - Error retention: {error_retention:.0f}%")
    print(f"   - Monthly savings: ${savings_per_month:.2f}")
    
    print(f"\n‚úÖ LipService Python SDK successfully integrated with PostHog-style logs!")
    print("=" * 80)


if __name__ == "__main__":
    asyncio.run(test_posthog_integration())

